\emph{Summary:}
The area of Information Theory was founded in 1948 by Claude Shannon.
It is a mathematical theory to reason about how much information is contained 
in certain data.
Equivalently, it is also a measure of uncertainty in information, and has thus 
plenty of application in security and cryptography.
This learning session covers the basic concept: Shannon entropy.

\emph{Intended learning outcomes:}
After the session you should be able
\begin{itemize}
  \item to \emph{apply} Shannon entropy in basic situations.
\end{itemize}

\emph{Reading:}
The concept of Shannon entropy, the main part of information theory, is treated 
in a few short texts:
\citetitle{Eckersley2010apo}~\cite{Eckersley2010apo} and
\citetitle{Ueltschi2013se}~\cite{Ueltschi2013se}.
