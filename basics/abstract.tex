The area of information theory was founded in 1948 by Claude Shannon.
It concerns information, e.g.\ how much information is contained in certain 
data.
Equivalently, it can also measure uncertainty in information, and has thus 
plenty of application in security and cryptography.
We will cover the basic theory of information theory --- entropy --- and its 
possible applications towards privacy.

In particular, after this session you should be able to
\begin{itemize}
  \item \emph{understand} which situations are relevant to analyse using 
    entropy.
  \item \emph{analyse} relevant situations using entropy and information gain 
    to yield insights into security and privacy.
\end{itemize}

The concept of entropy, the main part of information theory, is treated in 
a few short texts:
\citetitle{Eckersley2010apo}~\cite{Eckersley2010apo}
and applied in
\citetitle{Eckersley2010hui}~\cite{Eckersley2010hui},
but also in
\citetitle{Ueltschi2013se}~\cite{Ueltschi2013se}.
Other examples of its applications can be found in
\citetitle{Komanduri2011opa}~\cite{Komanduri2011opa},
\citetitle{MeasuringAnonymity}~\cite{MeasuringAnonymity} and
\citetitle{InfoTheoreticMetricForAnonymity}~\cite{InfoTheoreticMetricForAnonymity} 
(read either of these two papers).
